---
title: "Systematic Literature Review and Meta-analyses of Impact of Water, Sanitation, and Hygiene on the Transmission of Choler and Typhoid Fever."
output: html_notebook
editor_options:
  chunk_output_type: console
---


### Download Googlesheet
`googlesheets4` package seems to be a good option to study. I tried once, but failed because of authentication problem. It will take some time to figure this out. So I suggest we manually download the sheet for now. 
```{r}
# # googlesheet4 approach
# # install.packages("googlesheets4")
# library(googlesheets4)
# alba <- read_sheet('https://docs.google.com/spreadsheets/d/1XRI2av4sYU-1GMJxj-qYNfonu2GwB23VOxO39oVRMOY/edit#gid=1286174356')
# # failed

# I downloaded Primary_Articles_Typhoid.xlsx from the Google Drive and put it into the data folder

library(readxl)
path <- "data/input_articles.xlsx"
sheets <- excel_sheets(path)
xl_list <- lapply(excel_sheets(path), read_excel, path = path) 
names(xl_list) <- sheets

# combine multiple sheets into a single data frame
dat <- do.call(rbind, xl_list[2:20])
# failed, because the number of columns differ -- see the results from lapply(xl_list, ncol). We need to make the original data have the same columns
lapply(xl_list, ncol)
```


# The following codes work for old data I used to have and data need to be updated. So if we can solve the issue of different number of columns, I will update the codes.

### Parsing texts to extract upper and lower bounds of the confidence interval
```{r}
# parsing test
ci_text <- "2.5-21"
ci_text <- ".19-1.0"
lb <- grep("[0-9]*", ci_text, value = T)
library(stringr)
# as.numeric(str_extract_all(ci_text,"\\(?[0-9,.]+\\)?")[[1]])
as.numeric(str_extract_all(ci_text, "[0-9.]+")[[1]])
```

### Standard error computation
```{r}
calc_se <- function(lower, upper){
  se <- (upper - lower) / (2 * qnorm(0.975))
  return (se)
}
```

### random effects model
```{r}
library(dplyr)
# data for treated water category. You need your own data set
d <- data.table::fread("data/exposure_categorization_typhoid - Water treatment - Treated water.csv")
names(d)
OR <- ifelse(is.na(d$aOR), d$mOR, d$aOR)
ci_text <- ifelse(d$aCI=="", d$mCI, d$aCI)
ci <- str_extract_all(ci_text, "[0-9.]+")
lower <- as.numeric(sapply(ci, function(x) x[1]))
upper <- as.numeric(sapply(ci, function(x) x[2]))
se <- calc_se(lower = log(lower), upper = log(upper))
# create data frame to use 
dat <- data.frame(author = d$Author, log_OR = log(OR), SE = se)

# Frequentist approach
library(metafor)
res <- rma(yi = log_OR, sei = SE, data = dat) # Perform meta-analysis

summary(res)
# [1] 0.5655254

# Bayesian approach
# You may need Rtools and stan installed. 
library(brms)
priors <- c(prior(normal(0,1), class = Intercept),
            prior(cauchy(0,0.5), class = sd))

m_brm <- brm(log_OR|se(SE) ~ 1 + (1|author),
             data = dat,
             prior = priors,
             iter = 4000)

summary(m_brm)
# Population-Level Effects: 
#           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept    -0.56      0.22    -1.03    -0.13 1.00     2217     197
```


