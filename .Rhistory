# units of days^-1
parameters <- c(beta = 1,      # the infection rate
gamma = 0.1)   # the rate of recovery, which acts on
# those infected
# TIMESTEPS:
# Vector storing the sequence of timesteps to solve the model at
times <- seq(from = 0, to = 60, by = 1)
# from 0 to 60 days in daily intervals
# SIR MODEL FUNCTION:
# The model function takes as input arguments (in the following order):
# time, state and parameters
sir_model <- function(time, state, parameters) {
with(as.list(c(state, parameters)), {  # tell R to unpack variable names
# from the state and parameters inputs
# New: calculating the total population size N
N <- S+I+R # (the sum of the number of people in each compartment)
# New: defining liambda as a function of beta and I:
lambda <- beta * I/N
# Another option is simply replacing lambda with this
# expression in the differential equations below
# The differential equations
dS <- -lambda * S               # people move out of (-) the S
# compartment at a rate lambda
# (force of infection)
dI <- lambda * S - gamma * I    # people move into (+) the I compartment
# from S at a rate lambda,
# and move out of (-) the I compartment
# at a rate gamma (recovery)
dR <- gamma * I                 # people move into (+) the R compartment
# from I at a rate gamma
# Return the number of people in the S, I and R compartments at each
# timestep (in the same order as the input state variables)
return(list(c(dS, dI, dR)))
})
}
# MODEL OUTPUT (solving the differential equations):
# Solving the differential equations using the ode integration algorithm
output <- as.data.frame(ode(y = initial_state_values,
times = times,
func = sir_model,
parms = parameters))
# Plotting the output
output_long <- melt(as.data.frame(output), id = "time")                  # turn output dataset into long format
ggplot(data = output_long,                                               # specify object containing data to plot
aes(x = time, y = value, colour = variable, group = variable)) +  # assign columns to axes and groups
geom_line() +                                                          # represent data as lines
xlab("Time (days)")+                                                   # add label for x axis
ylab("Number of people") +                                             # add label for y axis
labs(colour = "Compartment")                                           # add legend title
output[output$time ==19,]
###
# LOAD THE PACKAGES:
library(deSolve)
library(reshape2)
library(ggplot2)
# MODEL INPUTS:
# Vector storing the initial number of people in each compartment (at timestep 0)
initial_state_values <- c(S = 1000000-1,  # the whole population we are modelling is susceptible to infection
I = 1,          # the epidemic starts with a single infected person
R = 0)          # there is no prior immunity in the population
# Vector storing the parameters describing the transition rates in units of days^-1
parameters <- c(beta = 0.5,     # the infection rate, which acts on susceptibles
gamma = 0.25)   # the rate of recovery, which acts on those infected
# TIMESTEPS:
# Vector storing the sequence of timesteps to solve the model at
times <- seq(from = 0, to = 100, by = 1)   # from 0 to 100 days in daily intervals
# SIR MODEL FUNCTION:
# The model function takes as input arguments (in the following order): time, state and parameters
sir_model <- function(time, state, parameters) {
with(as.list(c(state, parameters)), {   # tell R to unpack variable names from the state and parameters inputs
# Calculating the total population size N (the sum of the number of people in each compartment)
N <- S+I+R
# Defining lambda as a function of beta and I:
lambda <- beta * I/N
# The differential equations
dS <- -lambda * S               # people move out of (-) the S compartment at a rate lambda (force of infection)
dI <- lambda * S - gamma * I    # people move into (+) the I compartment from S at a rate lambda,
# and move out of (-) the I compartment at a rate gamma (recovery)
dR <- gamma * I                 # people move into (+) the R compartment from I at a rate gamma
# Return the number of people in the S, I and R compartments at each timestep
# (in the same order as the input state variables)
return(list(c(dS, dI, dR)))
})
}
# MODEL OUTPUT (solving the differential equations):
# Solving the differential equations using the ode integration algorithm
output <- as.data.frame(ode(y = initial_state_values,
times = times,
func = sir_model,
parms = parameters))
# PLOTTING THE OUTPUT
output_long <- melt(as.data.frame(output), id = "time")                  # turn output dataset into long format
# Adding a column for the proportion of the population in each compartment at each timestep
# One way of calculating this is dividing the number in each compartment by the total initial population size
# We can do this in this case because our population is closed, so the population size stays the same
# at every timestep
output_long$proportion <- output_long$value/sum(initial_state_values)
# Plot this new column
ggplot(data = output_long,                                               # specify object containing data to plot
aes(x = time, y = proportion, colour = variable, group = variable)) +  # assign columns to axes and groups
geom_line() +                                                          # represent data as lines
xlab("Time (days)")+                                                   # add label for x axis
ylab("Proportion of the population") +                                 # add label for y axis
labs(colour = "Compartment")                                           # add legend title
###### week 3
# LOAD THE PACKAGES:
library(deSolve)
library(reshape2)
library(ggplot2)
# MODEL INPUTS:
# Vector storing the initial number of people in each compartment (at timestep 0)
initial_state_values <- c(S = 1000000-1,   # the whole population we are modelling is susceptible to infection
I = 1,           # the epidemic starts with a single infected person
R = 0)           # there is no prior immunity in the population
# Vector storing the parameters describing the transition rates in units of days^-1
parameters <- c(beta = 0.4,      # the infection rate, which acts on susceptibles
gamma = 0.1)     # the rate of recovery, which acts on those infected
# TIMESTEPS:
# Vector storing the sequence of timesteps to solve the model at
times <- seq(from = 0, to = 100, by = 1)   # from 0 to 100 days in daily intervals
# SIR MODEL FUNCTION:
# The model function takes as input arguments (in the following order): time, state and parameters
sir_model <- function(time, state, parameters) {
with(as.list(c(state, parameters)), {  # tell R to unpack variable names from the state and parameters inputs
# Calculating the total population size N (the sum of the number of people in each compartment)
N <- S+I+R
# Defining lambda as a function of beta and I:
lambda <- beta * I/N
# The differential equations
dS <- -lambda * S               # people move out of (-) the S compartment at a rate lambda (force of infection)
dI <- lambda * S - gamma * I    # people move into (+) the I compartment from S at a rate lambda,
# and move out of (-) the I compartment at a rate gamma (recovery)
dR <- gamma * I                 # people move into (+) the R compartment from I at a rate gamma
# Return the number of people in the S, I and R compartments at each timestep
# (in the same order as the input state variables)
return(list(c(dS, dI, dR)))
})
}
# MODEL OUTPUT (solving the differential equations):
# Solving the differential equations using the ode integration algorithm
output <- as.data.frame(ode(y = initial_state_values,
times = times,
func = sir_model,
parms = parameters))
###
output_long <- melt(as.data.frame(output), id = "time")                  # turn output dataset into long format
# Calculating the proportion in each compartment as a column in the long-format output
output_long$proportion <- output_long$value/sum(initial_state_values)
# Plot the proportion of people in the S, I and R compartments over time
ggplot(data = output_long,                                               # specify object containing data to plot
aes(x = time, y = proportion, colour = variable, group = variable)) +  # assign columns to axes and groups
geom_line() +                                                          # represent data as lines
xlab("Time (days)")+                                                   # add label for x axis
ylab("Proportion of the population") +                                 # add label for y axis
labs(colour = "Compartment",                                           # add legend title
title = "Proportion susceptible, infected and recovered over time") +
theme(legend.position = "bottom")                                      # move legend to the bottom of the plot
# Calculating the effective reproduction number in a new column
output$reff <- parameters["beta"]/parameters["gamma"] *                  # R0 = beta/gamma
output$S/(output$S+output$I+output$R)                    # multiply R0 by the proportion susceptible
# at each timestep/for each row
# In this calculation, the total population size (output$S+output$I+output$R) is calculated for each timestep
# so this approach would also be appropriate if the population size varies over time
# Plot Reff
ggplot(data = output,                                                    # specify object containing data to plot
aes(x = time, y = reff)) +                                        # assign columns to axes and groups
geom_line() +                                                          # represent data as lines
xlab("Time (days)")+                                                   # add label for x axis
ylab("Reff") +                                                         # add label for y axis
labs(title = "Effective reproduction number over time")                # add plot title
library(readxl)
Policy_Webinar_Attendence_Duration <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy webinars/Participant duration/Policy Webinar Attendence Duration.xlsx")
View(Policy_Webinar_Attendence_Duration)
rm (list = ls ())
library(readxl)
Policy_Webinar_Attendence_Duration <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy webinars/Participant duration/Policy Webinar Attendence Duration.xlsx")
View(Policy_Webinar_Attendence_Duration)
library(extraDistr)
phcauchy(0.3, sigma = 0.3)
install.packages(brms)
brms::brm()
install.packages(brms)
install.packages(brms)
install.packages("brms")
install.packages(tidybayes)
install.packages("tidybayes")
library(brms)
priors <- c(prior(normal(0,1), class = Intercept),
prior(cauchy(0,0.5), class = sd))
priors
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
example(stan_model, package = "rstan", run.dontrun = TRUE)
---
title: "Systematic Literature Review and Meta-analyses of Impact of Water, Sanitation, and Hygiene on the Transmission of Choler and Typhoid Fever."
output: html_notebook
editor_options:
chunk_output_type: console
---
library(rstan)
Sys.setenv(DOWNLOAD_STATIC_LIBV8 = 1) # only necessary for Linux without the nodejs library / headers
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
library(rstan)
library(readxl)
Policy_workshop_poll_raw <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx",
sheet = "Day 1")
View(Policy_workshop_poll_raw)
Policy_workshop_poll_day1 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 1")
Policy_workshop_poll_day1 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 2")
Policy_workshop_poll_day1 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 1")
Policy_workshop_poll_day2 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 2")
Policy_workshop_poll_day3 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 3")
Policy_workshop_poll_EVIPNet <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "EVIPNet")
Policy_workshop_poll_day1 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 1")
Policy_workshop_poll_day2 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 2")
Policy_workshop_poll_day3 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 3")
Policy_workshop_poll_EVIPNet <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "EVIPNet")
View(Policy_workshop_poll_EVIPNet)
library(readxl)
Final_registration_report <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Final registration report.xlsx",
sheet = "Sheet1")
View(Final_registration_report)
Final_registration_report <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Final registration report.xlsx", sheet = "Sheet1")
Final_registration_report
View(Final_registration_report)
Policy_workshop_poll_day1 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 1")
Policy_workshop_poll_day2 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 2")
Policy_workshop_poll_day3 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 3")
Policy_workshop_poll_EVIPNet <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "EVIPNet")
Final_registration_report <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Final registration report.xlsx", sheet = "Sheet1")
Final_registration_report
View(Final_registration_report)
View(Policy_workshop_poll_day1)
day1 <- left_join(Policy_workshop_poll_day1, Final_registration_report,
by=c("Email" = "Email"))
library (readxl)
library (dplyr)
day1 <- left_join(Policy_workshop_poll_day1, Final_registration_report,
by=c("Email" = "Email"))
View(day1)
View(day1)
EVIPNet <- left_join(Policy_workshop_poll_EVIPNet, Final_registration_report,
by=c("Email" = "Email"))
EVIPNet
View(EVIPNet)
EVIPNet %>% count(`1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`)
View(EVIPNet)
EVIPNet %>% count(Sector, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`)
EVIPNet %>% count(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`)
library(janitor)
install.packages(janitor)
install.packages(janitor)
install.packages(gmodels)
install.packages("janitor")
library("janitor")
install.packages("gmodels")
library("gmodels")
tabyl(EVIPNet, `F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`)
tabyl(EVIPNet, `F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`) %>%
adorn_percentages("col") %>%
adorn_pct_formatting(digits = 1)
tabyl(EVIPNet, `F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`) %>%
adorn_percentages("row") %>%
adorn_pct_formatting(digits = 1)
CrossTable(EVIPNet$`1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`,
EVIPNet$Sector, prop.t=TRUE, prop.r=TRUE, prop.c=TRUE)
a <- CrossTable(EVIPNet$`1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`,
EVIPNet$Sector, prop.t=TRUE, prop.r=TRUE, prop.c=TRUE)
View(a)
str(a)
install.packages("crosstable")
library("crosstable")
ct1 = crosstable(EVIPNet,
c(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`),
by=am, total="both",
percent_pattern="{n} ({p_row}/{p_col})", percent_digits=0) %>%
as_flextable()
ct1
ct1 = crosstable(EVIPNet,
c(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`),
by=am, total="both",
percent_pattern="{n} ({p_row}/{p_col})", percent_digits=0) %>%
as_flextable()
ct1 = crosstable(EVIPNet,
c(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`),
by=am, total="both",
percent_pattern="{n} ({p_row}/{p_col})", percent_digits=0) %>%
ct1 = crosstable(EVIPNet,
c(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`),
by=am, total="both",
percent_pattern="{n} ({p_row}/{p_col})", percent_digits=0) %>%
as_flextable()
ct1 <- crosstable(EVIPNet,
c(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`),
by=am, total="both",
percent_pattern="{n} ({p_row}/{p_col})", percent_digits=0) %>%
as_flextable()
crosstable(EVIPNet,
c(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`),
by=am)%>%
as_flextable()
ct1 <- crosstable(EVIPNet,
c(`F Fellow`, `Sector`),
by=`1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`)%>%
as_flextable()
ct1
# load libraries
library (brms)
library (dplyr)
library (forcats)
library (ggplot2)
library (ggridges)
library (glue)
library (metafor)
library (readxl)
library (rstan)
library (stringr)
library (tidybayes)
library (googlesheets4)
library (data.table)
# remove all objects from workspace
rm (list = ls ())
setwd("~/GitHub/WASH_typhoid")
# start time
start_time <- Sys.time ()
print (paste0 ("start time = ", start_time))
# import data -- combined data
# input_articles <- read_excel("data/input_articles.xlsx")
dat <- read_sheet('https://docs.google.com/spreadsheets/d/1ArKNfpa124oPdrbGK1-9PnzRWWvffsxgOUfgCVs_p2Q/edit#gid=0', col_types = "ccccccccccc")
# parsing test
ci_text <- "2.5-21"
ci_text <- ".19-1.0"
lb <- grep("[0-9]*", ci_text, value = T)
# as.numeric(str_extract_all(ci_text,"\\(?[0-9,.]+\\)?")[[1]])
as.numeric(str_extract_all(ci_text, "[0-9.]+")[[1]])
calc_se <- function(lower, upper){
se <- (upper - lower) / (2 * qnorm(0.975))
return (se)
}
# rename the columns
dat <- dat %>% rename("mOR"  = "Crude OR",
"mCI"  = "Crude OR CI",
"aOR"  = "Adjusted OR",
"aCI"  = "Adjusted OR CI")
dat <- data.table(dat)
# remove the blank rows (n = 175 - 0 = 175)
dat <- dat[!(is.na(dat$mOR) & is.na(dat$aOR)),]
# remove values not classified (n = 79)
dat <- dat[!(dat$`JMP WASH Category` == "Trash"| dat$`JMP WASH Category` == "NOT WASH"),]
# remove reference values (n = 75)
dat <- dat[(dat$mOR != "ref" | is.na(dat$mOR)) & (dat$aOR != "ref" | is.na(dat$aOR)),]
# remove studies not using blood culture to confirm typhoid (n = 48)
# check the number of studies not using blood culture to confirm typhoid
# dat %>% filter(dat$Culture == "No") %>% count(Author, Culture)
dat <- dat[dat$Culture != "No",]
# inspect JMP WASH Category
unique(dat$`JMP WASH Category`)
dat %>% count(`JMP WASH Category`)
category_meta <- c("Improved water source",
"Water Source - Surface",
"Water treatment - Treated water",
"Water treatment - Untreated water",
"Sanitation - Open defecation",
"Hygiene - Basic",
"Hygiene - Limited")
# create baseline data
OR <- as.numeric(ifelse(is.na(dat$aOR), dat$mOR, dat$aOR))
ci_text <- ifelse(is.na(dat$aCI), dat$mCI, dat$aCI)
ci <- str_extract_all(ci_text, "[0-9.]+")
lower <- as.numeric(sapply(ci, function(x) x[1]))
upper <- as.numeric(sapply(ci, function(x) x[2]))
se <- calc_se(lower = log(lower), upper = log(upper))
input_data <- data.frame(category = dat$`JMP WASH Category`,
author   = dat$Author,
log_OR   = log(OR),
SE       = se)
meta_freq <- function(input_category){
input_dat_freq <- input_data %>% filter(input_data$category == input_category)
res <- rma(yi = exp(log_OR), sei = exp(SE), data = input_dat_freq) # Perform meta-analysis
summary <- summary(res)
return(summary)}
# summary result -- for each categories
category_meta
lapply(category_meta, meta_freq)
meta_baye <- function(input_category){
input_dat_baye <- input_data %>% filter(input_data$category == input_category)
priors <- c(prior(normal(0,1), class = Intercept),
prior(cauchy(0,0.5), class = sd))
m_brm <- brm(log_OR|se(SE) ~ 1 + (1|author),
data = input_dat_baye,
prior = priors,
iter = 4000)
# summary(m.brm)
return(m_brm)}
# m_brm <- meta_baye("Sanitation - Open defecation")
# summary(meta_baye("Improved water source"))
# summary(meta_baye("Water Source - Surface"))
# summary(meta_baye("Water treatment - Treated water"))
# summary(meta_baye("Water treatment - Untreated water"))
# summary(meta_baye("Sanitation - Open defecation"))
# summary(meta_baye("Hygiene - Basic"))
# summary(meta_baye("Hygiene - Limited"))
pooled_effect_draws <- function(m_brm){
# extract the posterior distribution for each study
study.draws <- spread_draws(m_brm, r_author[author,], b_Intercept) %>%
mutate(b_Intercept = r_author + b_Intercept)
# generate the distribution of the pooled effect
pooled.effect.draws <- spread_draws(m_brm, b_Intercept) %>%
mutate(author = "Pooled Effect")
forest.data <- bind_rows(study.draws,
pooled.effect.draws) %>%
ungroup() %>%
# clean the study labels
mutate(author = str_replace_all(author, ".et.al.", " et al.")) %>%
# reorder the study factor levels by effect size (high to low).
mutate(author = reorder(author, b_Intercept)) %>%
# use exp() to revert it to Odd Ratio
mutate(b_Intercept = exp(b_Intercept))
return(forest.data)}
create_forestplot <- function(m_brm,
forest.data,
x_limit,
title_name){
# display the effect size
forest.data.summary <- group_by(forest.data, author) %>%
median_qi(b_Intercept)
forestplot <- ggplot(aes(b_Intercept,
relevel(author, "Pooled Effect",
after = Inf)),
data = forest.data) +
# Add vertical lines for pooled effect and CI
geom_vline(xintercept = data.table(forest.data.summary)[author == "Pooled Effect", b_Intercept],
color = "grey", size = 1) +
geom_vline(xintercept = data.table(forest.data.summary)[author == "Pooled Effect", c(.lower, .upper)],
color = "grey", linetype = 2) +
geom_vline(xintercept = 1, color = "black",
size = 1) +
scale_x_continuous(limits = c(0, x_limit)) +
# Add densities
geom_density_ridges(fill = "grey",
rel_min_height = 0.01,
col = NA, scale = 1,
alpha = 0.8) +
geom_pointintervalh(data = forest.data.summary,
size = 1) +
# Add text and labels
geom_text(data = mutate_if(forest.data.summary,
is.numeric, round, 2),
aes(label = glue("{b_Intercept} [{.lower}, {.upper}]"),
x = Inf), hjust = "inward") +
labs(x = "Odd Ratio [95% Credible Interval]", # summary measure
y = element_blank()) +
theme_minimal() +
ggtitle(paste(title_name)) +
theme(plot.title = element_text(hjust=0.5, vjust=2, size = 15))
return(forestplot)
} # end of function -- create_forest_plot
forest_plot <- function(input_category, x_limit){
m_brm_input <- meta_baye(input_category)
forest_data <- pooled_effect_draws(m_brm_input)
forestplot  <- create_forestplot(m_brm       = m_brm_input,
forest.data = forest_data,
x_limit     = x_limit,
title_name  = input_category)
# save plot
ggsave (filename = paste(input_category, ".png"),
path = "figures",
width = 8,
height = 6,
dpi = 600)
return(forestplot)}
forest_plot(input_category = "Sanitation - Open defecation",
x_limit        = 7)
# load libraries
library (brms)
library (dplyr)
library (forcats)
library (ggplot2)
library (ggridges)
library (glue)
library (metafor)
library (readxl)
library (rstan)
library (stringr)
library (tidybayes)
library (googlesheets4)
library (data.table)
# remove all objects from workspace
rm (list = ls ())
setwd("~/GitHub/WASH_typhoid")
# start time
start_time <- Sys.time ()
print (paste0 ("start time = ", start_time))
# import data -- combined data
# input_articles <- read_excel("data/input_articles.xlsx")
dat <- read_sheet('https://docs.google.com/spreadsheets/d/1ArKNfpa124oPdrbGK1-9PnzRWWvffsxgOUfgCVs_p2Q/edit#gid=0', col_types = "ccccccccccc")
meta_baye <- function(input_category){
input_dat_baye <- input_data %>% filter(input_data$category == input_category)
priors <- c(prior(normal(0,1), class = Intercept),
prior(cauchy(0,0.5), class = sd))
m_brm <- brm(log_OR|se(SE) ~ 1 + (1|author),
data = input_dat_baye,
prior = priors,
iter = 4000)
# summary(m.brm)
return(m_brm)}
# m_brm <- meta_baye("Sanitation - Open defecation")
install.packages("devtools")
devtools::install_github("mcguinlu/robvis")
