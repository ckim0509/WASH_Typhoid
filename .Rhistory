output_long$proportion <- output_long$value/sum(initial_state_values)
# Plot the proportion of people in the S, I and R compartments over time
ggplot(data = output_long,                                               # specify object containing data to plot
aes(x = time, y = proportion, colour = variable, group = variable)) +  # assign columns to axes and groups
geom_line() +                                                          # represent data as lines
xlab("Time (days)")+                                                   # add label for x axis
ylab("Proportion of the population") +                                 # add label for y axis
labs(colour = "Compartment",                                           # add legend title
title = "Proportion susceptible, infected and recovered over time") +
theme(legend.position = "bottom")                                      # move legend to the bottom of the plot
# Calculating the effective reproduction number in a new column
output$reff <- parameters["beta"]/parameters["gamma"] *                  # R0 = beta/gamma
output$S/(output$S+output$I+output$R)                    # multiply R0 by the proportion susceptible
# at each timestep/for each row
# In this calculation, the total population size (output$S+output$I+output$R) is calculated for each timestep
# so this approach would also be appropriate if the population size varies over time
# Plot Reff
ggplot(data = output,                                                    # specify object containing data to plot
aes(x = time, y = reff)) +                                        # assign columns to axes and groups
geom_line() +                                                          # represent data as lines
xlab("Time (days)")+                                                   # add label for x axis
ylab("Reff") +                                                         # add label for y axis
labs(title = "Effective reproduction number over time")                # add plot title
library(readxl)
Policy_Webinar_Attendence_Duration <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy webinars/Participant duration/Policy Webinar Attendence Duration.xlsx")
View(Policy_Webinar_Attendence_Duration)
rm (list = ls ())
library(readxl)
Policy_Webinar_Attendence_Duration <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy webinars/Participant duration/Policy Webinar Attendence Duration.xlsx")
View(Policy_Webinar_Attendence_Duration)
library(extraDistr)
phcauchy(0.3, sigma = 0.3)
install.packages(brms)
brms::brm()
install.packages(brms)
install.packages(brms)
install.packages("brms")
install.packages(tidybayes)
install.packages("tidybayes")
library(brms)
priors <- c(prior(normal(0,1), class = Intercept),
prior(cauchy(0,0.5), class = sd))
priors
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
example(stan_model, package = "rstan", run.dontrun = TRUE)
---
title: "Systematic Literature Review and Meta-analyses of Impact of Water, Sanitation, and Hygiene on the Transmission of Choler and Typhoid Fever."
output: html_notebook
editor_options:
chunk_output_type: console
---
library(rstan)
Sys.setenv(DOWNLOAD_STATIC_LIBV8 = 1) # only necessary for Linux without the nodejs library / headers
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
library(rstan)
library(readxl)
Policy_workshop_poll_raw <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx",
sheet = "Day 1")
View(Policy_workshop_poll_raw)
Policy_workshop_poll_day1 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 1")
Policy_workshop_poll_day1 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 2")
Policy_workshop_poll_day1 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 1")
Policy_workshop_poll_day2 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 2")
Policy_workshop_poll_day3 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 3")
Policy_workshop_poll_EVIPNet <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "EVIPNet")
Policy_workshop_poll_day1 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 1")
Policy_workshop_poll_day2 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 2")
Policy_workshop_poll_day3 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 3")
Policy_workshop_poll_EVIPNet <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "EVIPNet")
View(Policy_workshop_poll_EVIPNet)
library(readxl)
Final_registration_report <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Final registration report.xlsx",
sheet = "Sheet1")
View(Final_registration_report)
Final_registration_report <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Final registration report.xlsx", sheet = "Sheet1")
Final_registration_report
View(Final_registration_report)
Policy_workshop_poll_day1 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 1")
Policy_workshop_poll_day2 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 2")
Policy_workshop_poll_day3 <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "Day 3")
Policy_workshop_poll_EVIPNet <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Policy workshop poll_raw.xlsx", sheet = "EVIPNet")
Final_registration_report <- read_excel("C:/Users/chaelin.kim/OneDrive - International Vaccine Institute/RADAAR project/Policy workshop/Zoom poll results/Final registration report.xlsx", sheet = "Sheet1")
Final_registration_report
View(Final_registration_report)
View(Policy_workshop_poll_day1)
day1 <- left_join(Policy_workshop_poll_day1, Final_registration_report,
by=c("Email" = "Email"))
library (readxl)
library (dplyr)
day1 <- left_join(Policy_workshop_poll_day1, Final_registration_report,
by=c("Email" = "Email"))
View(day1)
View(day1)
EVIPNet <- left_join(Policy_workshop_poll_EVIPNet, Final_registration_report,
by=c("Email" = "Email"))
EVIPNet
View(EVIPNet)
EVIPNet %>% count(`1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`)
View(EVIPNet)
EVIPNet %>% count(Sector, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`)
EVIPNet %>% count(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`)
library(janitor)
install.packages(janitor)
install.packages(janitor)
install.packages(gmodels)
install.packages("janitor")
library("janitor")
install.packages("gmodels")
library("gmodels")
tabyl(EVIPNet, `F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`)
tabyl(EVIPNet, `F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`) %>%
adorn_percentages("col") %>%
adorn_pct_formatting(digits = 1)
tabyl(EVIPNet, `F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`) %>%
adorn_percentages("row") %>%
adorn_pct_formatting(digits = 1)
CrossTable(EVIPNet$`1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`,
EVIPNet$Sector, prop.t=TRUE, prop.r=TRUE, prop.c=TRUE)
a <- CrossTable(EVIPNet$`1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`,
EVIPNet$Sector, prop.t=TRUE, prop.r=TRUE, prop.c=TRUE)
View(a)
str(a)
install.packages("crosstable")
library("crosstable")
ct1 = crosstable(EVIPNet,
c(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`),
by=am, total="both",
percent_pattern="{n} ({p_row}/{p_col})", percent_digits=0) %>%
as_flextable()
ct1
ct1 = crosstable(EVIPNet,
c(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`),
by=am, total="both",
percent_pattern="{n} ({p_row}/{p_col})", percent_digits=0) %>%
as_flextable()
ct1 = crosstable(EVIPNet,
c(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`),
by=am, total="both",
percent_pattern="{n} ({p_row}/{p_col})", percent_digits=0) %>%
ct1 = crosstable(EVIPNet,
c(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`),
by=am, total="both",
percent_pattern="{n} ({p_row}/{p_col})", percent_digits=0) %>%
as_flextable()
ct1 <- crosstable(EVIPNet,
c(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`),
by=am, total="both",
percent_pattern="{n} ({p_row}/{p_col})", percent_digits=0) %>%
as_flextable()
crosstable(EVIPNet,
c(`F Fellow`, `1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`),
by=am)%>%
as_flextable()
ct1 <- crosstable(EVIPNet,
c(`F Fellow`, `Sector`),
by=`1.Are countries able to systematically analyze and translate emerging AMR/U/C data and evidence to effectively inform or influence policy?`)%>%
as_flextable()
ct1
# load libraries
library (brms)
library (dplyr)
library (forcats)
library (ggplot2)
library (ggridges)
library (glue)
library (metafor)
library (readxl)
library (rstan)
library (stringr)
library (tidybayes)
library (googlesheets4)
library (data.table)
# remove all objects from workspace
rm (list = ls ())
setwd("~/GitHub/WASH_typhoid")
# start time
start_time <- Sys.time ()
print (paste0 ("start time = ", start_time))
# import data -- combined data
# input_articles <- read_excel("data/input_articles.xlsx")
dat <- read_sheet('https://docs.google.com/spreadsheets/d/1ArKNfpa124oPdrbGK1-9PnzRWWvffsxgOUfgCVs_p2Q/edit#gid=0', col_types = "ccccccccccc")
### Parsing texts to extract upper and lower bounds of the confidence interval
```{r}
# parsing test
ci_text <- "2.5-21"
ci_text <- ".19-1.0"
lb <- grep("[0-9]*", ci_text, value = T)
# as.numeric(str_extract_all(ci_text,"\\(?[0-9,.]+\\)?")[[1]])
as.numeric(str_extract_all(ci_text, "[0-9.]+")[[1]])
```
### Standard error computation
```{r}
calc_se <- function(lower, upper){
se <- (upper - lower) / (2 * qnorm(0.975))
return (se)
}
```
### Data cleaning
```{r}
# rename the columns
dat <- dat %>% rename("mOR"  = "Crude OR",
"mCI"  = "Crude OR CI",
"aOR"  = "Adjusted OR",
"aCI"  = "Adjusted OR CI")
dat <- data.table(dat)
# remove the blank rows (n = 175 - 0 = 175)
dat <- dat[!(is.na(dat$mOR) & is.na(dat$aOR)),]
# remove values not classified (n = 79)
dat <- dat[!(dat$`JMP WASH Category` == "Trash"| dat$`JMP WASH Category` == "NOT WASH"),]
# remove reference values (n = 75)
dat <- dat[(dat$mOR != "ref" | is.na(dat$mOR)) & (dat$aOR != "ref" | is.na(dat$aOR)),]
# remove studies not using blood culture to confirm typhoid (n = 48)
# check the number of studies not using blood culture to confirm typhoid
# dat %>% filter(dat$Culture == "No") %>% count(Author, Culture)
dat <- dat[dat$Culture != "No",]
```
### Create analysis baseline
```{r}
# inspect JMP WASH Category
unique(dat$`JMP WASH Category`)
dat %>% count(`JMP WASH Category`)
category_meta <- c("Improved water source",
"Water Source - Surface",
"Water treatment - Treated water",
"Water treatment - Untreated water",
"Sanitation - Open defecation",
"Hygiene - Basic",
"Hygiene - Limited")
# create baseline data
OR <- as.numeric(ifelse(is.na(dat$aOR), dat$mOR, dat$aOR))
ci_text <- ifelse(is.na(dat$aCI), dat$mCI, dat$aCI)
ci <- str_extract_all(ci_text, "[0-9.]+")
lower <- as.numeric(sapply(ci, function(x) x[1]))
upper <- as.numeric(sapply(ci, function(x) x[2]))
se <- calc_se(lower = log(lower), upper = log(upper))
input_data <- data.frame(category = dat$`JMP WASH Category`,
author   = dat$Author,
log_OR   = log(OR),
SE       = se)
```
### Frequentist Meta-Analysis
```{r}
meta_freq <- function(input_category){
input_dat_freq <- input_data %>% filter(input_data$category == input_category)
res <- rma(yi = exp(log_OR), sei = exp(SE), data = input_dat_freq) # Perform meta-analysis
summary <- summary(res)
return(summary)}
# summary result -- for each categories
category_meta
lapply(category_meta, meta_freq)
```
### Bayesian Meta-Analysis
```{r}
meta_baye <- function(input_category){
input_dat_baye <- input_data %>% filter(input_data$category == input_category)
priors <- c(prior(normal(0,1), class = Intercept),
prior(cauchy(0,0.5), class = sd))
m_brm <- brm(log_OR|se(SE) ~ 1 + (1|author),
data = input_dat_baye,
prior = priors,
iter = 4000)
# summary(m.brm)
return(m_brm)}
# m_brm <- meta_baye("Sanitation - Open defecation")
```
### Model inspection -- check Rhat wheather it is smaller than 1.01
```{r}
# summary(meta_baye("Improved water source"))
# summary(meta_baye("Water Source - Surface"))
# summary(meta_baye("Water treatment - Treated water"))
# summary(meta_baye("Water treatment - Untreated water"))
# summary(meta_baye("Sanitation - Open defecation"))
# summary(meta_baye("Hygiene - Basic"))
# summary(meta_baye("Hygiene - Limited"))
```
### Prepare the data to generate the plot
```{r}
pooled_effect_draws <- function(m_brm){
# extract the posterior distribution for each study
study.draws <- spread_draws(m_brm, r_author[author,], b_Intercept) %>%
mutate(b_Intercept = r_author + b_Intercept)
# generate the distribution of the pooled effect
pooled.effect.draws <- spread_draws(m_brm, b_Intercept) %>%
mutate(author = "Pooled Effect")
forest.data <- bind_rows(study.draws,
pooled.effect.draws) %>%
ungroup() %>%
# clean the study labels
mutate(author = str_replace_all(author, ".et.al.", " et al.")) %>%
# reorder the study factor levels by effect size (high to low).
mutate(author = reorder(author, b_Intercept)) %>%
# use exp() to revert it to Odd Ratio
mutate(b_Intercept = exp(b_Intercept))
return(forest.data)}
```
### Function to generate forest plot
```{r}
create_forestplot <- function(m_brm,
forest.data,
x_limit,
title_name){
# display the effect size
forest.data.summary <- group_by(forest.data, author) %>%
median_qi(b_Intercept)
forestplot <- ggplot(aes(b_Intercept,
relevel(author, "Pooled Effect",
after = Inf)),
data = forest.data) +
# Add vertical lines for pooled effect and CI
geom_vline(xintercept = data.table(forest.data.summary)[author == "Pooled Effect", b_Intercept],
color = "grey", size = 1) +
geom_vline(xintercept = data.table(forest.data.summary)[author == "Pooled Effect", c(.lower, .upper)],
color = "grey", linetype = 2) +
geom_vline(xintercept = 1, color = "black",
size = 1) +
scale_x_continuous(limits = c(0, x_limit)) +
# Add densities
geom_density_ridges(fill = "grey",
rel_min_height = 0.01,
col = NA, scale = 1,
alpha = 0.8) +
geom_pointintervalh(data = forest.data.summary,
size = 1) +
# Add text and labels
geom_text(data = mutate_if(forest.data.summary,
is.numeric, round, 2),
aes(label = glue("{b_Intercept} [{.lower}, {.upper}]"),
x = Inf), hjust = "inward") +
labs(x = "Odd Ratio [95% Credible Interval]", # summary measure
y = element_blank()) +
theme_minimal() +
ggtitle(paste(title_name)) +
theme(plot.title = element_text(hjust=0.5, vjust=2, size = 15))
return(forestplot)
} # end of function -- create_forest_plot
```
### Combine functions to generate and save forest plot
```{r}
forest_plot <- function(input_category, x_limit){
m_brm_input <- meta_baye(input_category)
forest_data <- pooled_effect_draws(m_brm_input)
forestplot  <- create_forestplot(m_brm       = m_brm_input,
forest.data = forest_data,
x_limit     = x_limit,
title_name  = input_category)
# save plot
ggsave (filename = paste(input_category, ".png"),
path = "figures",
width = 8,
height = 6,
dpi = 600)
return(forestplot)}
```
# import data -- combined data
# input_articles <- read_excel("data/input_articles.xlsx")
dat <- read_sheet('https://docs.google.com/spreadsheets/d/1ArKNfpa124oPdrbGK1-9PnzRWWvffsxgOUfgCVs_p2Q/edit#gid=0', col_types = "ccccccccccc")
# parsing test
ci_text <- "2.5-21"
ci_text <- ".19-1.0"
lb <- grep("[0-9]*", ci_text, value = T)
# as.numeric(str_extract_all(ci_text,"\\(?[0-9,.]+\\)?")[[1]])
as.numeric(str_extract_all(ci_text, "[0-9.]+")[[1]])
calc_se <- function(lower, upper){
se <- (upper - lower) / (2 * qnorm(0.975))
return (se)
}
# rename the columns
dat <- dat %>% rename("mOR"  = "Crude OR",
"mCI"  = "Crude OR CI",
"aOR"  = "Adjusted OR",
"aCI"  = "Adjusted OR CI")
dat <- data.table(dat)
# remove the blank rows (n = 175 - 0 = 175)
dat <- dat[!(is.na(dat$mOR) & is.na(dat$aOR)),]
# remove values not classified (n = 79)
dat <- dat[!(dat$`JMP WASH Category` == "Trash"| dat$`JMP WASH Category` == "NOT WASH"),]
# remove reference values (n = 75)
dat <- dat[(dat$mOR != "ref" | is.na(dat$mOR)) & (dat$aOR != "ref" | is.na(dat$aOR)),]
# remove studies not using blood culture to confirm typhoid (n = 48)
# check the number of studies not using blood culture to confirm typhoid
# dat %>% filter(dat$Culture == "No") %>% count(Author, Culture)
dat <- dat[dat$Culture != "No",]
# inspect JMP WASH Category
unique(dat$`JMP WASH Category`)
dat %>% count(`JMP WASH Category`)
category_meta <- c("Improved water source",
"Water Source - Surface",
"Water treatment - Treated water",
"Water treatment - Untreated water",
"Sanitation - Open defecation",
"Hygiene - Basic",
"Hygiene - Limited")
# create baseline data
OR <- as.numeric(ifelse(is.na(dat$aOR), dat$mOR, dat$aOR))
ci_text <- ifelse(is.na(dat$aCI), dat$mCI, dat$aCI)
ci <- str_extract_all(ci_text, "[0-9.]+")
lower <- as.numeric(sapply(ci, function(x) x[1]))
upper <- as.numeric(sapply(ci, function(x) x[2]))
se <- calc_se(lower = log(lower), upper = log(upper))
input_data <- data.frame(category = dat$`JMP WASH Category`,
author   = dat$Author,
log_OR   = log(OR),
SE       = se)
meta_freq <- function(input_category){
input_dat_freq <- input_data %>% filter(input_data$category == input_category)
res <- rma(yi = exp(log_OR), sei = exp(SE), data = input_dat_freq) # Perform meta-analysis
summary <- summary(res)
return(summary)}
# summary result -- for each categories
category_meta
lapply(category_meta, meta_freq)
meta_baye <- function(input_category){
input_dat_baye <- input_data %>% filter(input_data$category == input_category)
priors <- c(prior(normal(0,1), class = Intercept),
prior(cauchy(0,0.5), class = sd))
m_brm <- brm(log_OR|se(SE) ~ 1 + (1|author),
data = input_dat_baye,
prior = priors,
iter = 4000)
# summary(m.brm)
return(m_brm)}
# m_brm <- meta_baye("Sanitation - Open defecation")
# summary(meta_baye("Improved water source"))
# summary(meta_baye("Water Source - Surface"))
# summary(meta_baye("Water treatment - Treated water"))
# summary(meta_baye("Water treatment - Untreated water"))
# summary(meta_baye("Sanitation - Open defecation"))
# summary(meta_baye("Hygiene - Basic"))
# summary(meta_baye("Hygiene - Limited"))
pooled_effect_draws <- function(m_brm){
# extract the posterior distribution for each study
study.draws <- spread_draws(m_brm, r_author[author,], b_Intercept) %>%
mutate(b_Intercept = r_author + b_Intercept)
# generate the distribution of the pooled effect
pooled.effect.draws <- spread_draws(m_brm, b_Intercept) %>%
mutate(author = "Pooled Effect")
forest.data <- bind_rows(study.draws,
pooled.effect.draws) %>%
ungroup() %>%
# clean the study labels
mutate(author = str_replace_all(author, ".et.al.", " et al.")) %>%
# reorder the study factor levels by effect size (high to low).
mutate(author = reorder(author, b_Intercept)) %>%
# use exp() to revert it to Odd Ratio
mutate(b_Intercept = exp(b_Intercept))
return(forest.data)}
create_forestplot <- function(m_brm,
forest.data,
x_limit,
title_name){
# display the effect size
forest.data.summary <- group_by(forest.data, author) %>%
median_qi(b_Intercept)
forestplot <- ggplot(aes(b_Intercept,
relevel(author, "Pooled Effect",
after = Inf)),
data = forest.data) +
# Add vertical lines for pooled effect and CI
geom_vline(xintercept = data.table(forest.data.summary)[author == "Pooled Effect", b_Intercept],
color = "grey", size = 1) +
geom_vline(xintercept = data.table(forest.data.summary)[author == "Pooled Effect", c(.lower, .upper)],
color = "grey", linetype = 2) +
geom_vline(xintercept = 1, color = "black",
size = 1) +
scale_x_continuous(limits = c(0, x_limit)) +
# Add densities
geom_density_ridges(fill = "grey",
rel_min_height = 0.01,
col = NA, scale = 1,
alpha = 0.8) +
geom_pointintervalh(data = forest.data.summary,
size = 1) +
# Add text and labels
geom_text(data = mutate_if(forest.data.summary,
is.numeric, round, 2),
aes(label = glue("{b_Intercept} [{.lower}, {.upper}]"),
x = Inf), hjust = "inward") +
labs(x = "Odd Ratio [95% Credible Interval]", # summary measure
y = element_blank()) +
theme_minimal() +
ggtitle(paste(title_name)) +
theme(plot.title = element_text(hjust=0.5, vjust=2, size = 15))
return(forestplot)
} # end of function -- create_forest_plot
forest_plot <- function(input_category, x_limit){
m_brm_input <- meta_baye(input_category)
forest_data <- pooled_effect_draws(m_brm_input)
forestplot  <- create_forestplot(m_brm       = m_brm_input,
forest.data = forest_data,
x_limit     = x_limit,
title_name  = input_category)
# save plot
ggsave (filename = paste(input_category, ".png"),
path = "figures",
width = 8,
height = 6,
dpi = 600)
return(forestplot)}
forest_plot(input_category = "Hygiene - Basic",
x_limit        = 3)
forest_plot(input_category = "Hygiene - Limited",
x_limit        = 10)
# return to source directory
setwd (source_wd)
# end time
end_time <- Sys.time ()
print (paste0 ("end time = ", end_time))
print (Sys.time () - start_time)
